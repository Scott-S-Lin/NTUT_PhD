{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "Lab7_scott.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scott-S-Lin/NTUT_PhD/blob/main/Lab7_scott.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_CqIrDfph2h"
      },
      "source": [
        "# TensorBoard進階技巧"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOru2DFWph2j"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab7.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab7.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h5fjDAhph2l"
      },
      "source": [
        "## tf.summary\n",
        "\n",
        "tf.summary是TensorFlow提供TensorBoard低階API指令，主要是用來紀錄log檔。\n",
        "以下整理了幾個常用功能：\n",
        "- tf.scalar：儲存顯示如損失、指標或學習率等的變化趨勢。\n",
        "- tf.image：儲存顯示影像。\n",
        "- tf.audio：儲存顯示可播放的音頻。\n",
        "- tf.histogram：儲存顯示模型權重。\n",
        "- tf.text：儲存顯示一段文字。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnk_1xfnph2m"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4yCgTr4ph2n"
      },
      "source": [
        "### 創建TensorBoard log檔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzoT_onBph2n"
      },
      "source": [
        "summary_writer = tf.summary.create_file_writer('lab7-logs-summary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlKMXIi3ph2o"
      },
      "source": [
        "### Scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fj4OySuph2o"
      },
      "source": [
        "# 在0~2π之間產生100個點\n",
        "x = np.linspace(0, 2 * np.pi , 100)\n",
        "# 將100個點帶入sin函數中\n",
        "data = np.sin(x)\n",
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔\n",
        "    for i, y in enumerate(data):\n",
        "        tf.summary.scalar('sin', y, step=i)  # 存入數值(y為數值，i為時間軸)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R365i7fCph2p"
      },
      "source": [
        "### Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEUzhPc2ph2q"
      },
      "source": [
        "1. 儲存一張影像在紀錄檔中並顯示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnkRhwWuph2q"
      },
      "source": [
        "# 建立讀取影像的函數\n",
        "def read_img(file):\n",
        "    image_string = tf.io.read_file(file)  # 讀取檔案\n",
        "    # 將讀入檔案以影像格式來解碼\n",
        "    image_decode = tf.image.decode_image(image_string)\n",
        "    # 將影像增加一個維度(number,height,width,channel)方便之後存入紀錄檔中\n",
        "    # image_decode = tf.expand_dims(image_decode, axis=0)\n",
        "    return image_decode\n",
        "\n",
        "img = read_img('image/airplane.png')  # 讀入影像資訊\n",
        "plt.imshow(img)  # 顯示讀入的影像資訊"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PCM2Cxph2t"
      },
      "source": [
        "image_string = tf.io.read_file('image/airplane.png')  # 讀取檔案\n",
        "image_decode = tf.image.decode_image(image_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "548xYGlfph2t"
      },
      "source": [
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔\n",
        "    tf.summary.image(\"Airplane\", [image_decode], step=0)  # 存入影像資訊"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycmnc3oTph2u"
      },
      "source": [
        "2. 一次儲存五張影像到紀錄檔中並顯示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7-JZP5dhph2u"
      },
      "source": [
        "!ls image/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGQQigRJph2v"
      },
      "source": [
        "img_files = ['airplane_zoom.png', 'airplane_flip.png', 'airplane_color.png', 'airplane_rot.png',\n",
        "             'airplane.png']  # 創建一個陣列用來儲存讀入的影像 \n",
        "\n",
        "imgs = [] \n",
        "\n",
        "for file in img_files: \n",
        "    imgs.append(read_img('image/'+file))  # 讀取影像並存入陣列中 \n",
        "\n",
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔 \n",
        "    # 一次存入五張影像(注意:如果max_outputs沒設定為5，就只會儲存3張影像) \n",
        "    tf.summary.image(\"Airplane Augmentation\", imgs, max_outputs=5, step=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtB2Z1Y1ph2w"
      },
      "source": [
        "3. 將五張影像以不同Step(時間)儲存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8PCuYKCph2w"
      },
      "source": [
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔\n",
        "    # 每次儲存一張影像，並儲存在不同Step中\n",
        "    for i, img in enumerate(imgs):\n",
        "        tf.summary.image(\"Save image each step\", [img], step=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHa_U84Wph2w"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GntTz8Wph2x"
      },
      "source": [
        "# 建立一個陣列，裡面包含了對話記錄\n",
        "texts = [\"小明：Cubee小助理最近好想學深度學習的技術哦!\", \n",
        "         \"Cubee：這是當然的阿，這可現今最火的技術呢!\", \n",
        "         \"小明：那我該如何入門呢?\", \n",
        "         \"Cubee：推薦你一本書「輕鬆學會Google TensorFlow2.0深度學習」。\", \n",
        "         \"小明：這本書沒有深度學習經驗的人也能學會嗎?\", \n",
        "         \"Cubee：這是當然的，你只需要基礎Python能力就可以學會了!\", \n",
        "         \"小明：太好了那我要趕快去買了!\"]\n",
        "\n",
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔\n",
        "    # 將每一段字串資訊以不同Step存入到記錄檔中\n",
        "    for i, text in enumerate(texts):\n",
        "        tf.summary.text(\"Chat record\", text, step=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78nd3avsph2x"
      },
      "source": [
        "### Audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2I_rF1uph2x"
      },
      "source": [
        "# 建立讀取音訊的函數\n",
        "def read_audio(file):\n",
        "    audio_string = tf.io.read_file(file)  # 讀取檔案\n",
        "    # 將讀入檔案以音訊格式來解碼\n",
        "    audio, fs = tf.audio.decode_wav(audio_string)\n",
        "    # 因為tf.summary.audio要求輸入格式為[k(clips), t(frames), c(channels)]\n",
        "    # 而解碼後的音訊只有[t(frames), c(channels)]，所以需要增加一個維度給音訊\n",
        "    audio = tf.expand_dims(audio, axis=0)\n",
        "    return audio, fs\n",
        "\n",
        "audio, fs = read_audio('./audio/cat.wav')  # 讀取音訊檔\n",
        "\n",
        "with summary_writer.as_default():  # summary_writer作為預設寫入的紀錄檔\n",
        "    tf.summary.audio('cat', audio, fs, step=0)  # 存入音訊資訊"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lL6vr_iph2y"
      },
      "source": [
        "### Histogram\n",
        "\n",
        "目前 TensorFlow-gpu 2.0-alpha有問題，等待下一版修復。\n",
        "\n",
        "https://github.com/tensorflow/tensorboard/issues/1993"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q15X9Hv-ph2y"
      },
      "source": [
        "建立一個常態分佈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70t9kLuCph2z"
      },
      "source": [
        "data = tf.random.normal([64, 100], dtype=tf.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E9Ri6vaph2z"
      },
      "source": [
        "儲存常態分佈分佈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6iVOhpiph2z"
      },
      "source": [
        "with summary_writer.as_default():\n",
        "    tf.summary.histogram('Normal distribution', data, step=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc5A9mpCph20"
      },
      "source": [
        "儲存多個常態分佈，並且各個之間平均值都相差0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtO_-s4ph20"
      },
      "source": [
        "with summary_writer.as_default():\n",
        "    for i, offset in enumerate(tf.range(0, 10, delta=0.1, dtype=tf.float64)):\n",
        "        tf.summary.histogram('Normal distribution 2', data+offset, step=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRNA4qMT1J1n"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq89oi7M1cpC"
      },
      "source": [
        "tensorboard --logdir lab7-logs-summary/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWc9Tnysph20"
      },
      "source": [
        "# 實驗一：使用tf.summary.image紀錄訓練結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkAEM3Ynph21"
      },
      "source": [
        "### Import 必要套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMc1knvKph21"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from preprocessing import parse_aug_fn, parse_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIKl_UG7ph21"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oEe9PBph22"
      },
      "source": [
        "Confusion matrix函數：透過tf.math.confusion_matrix來計算Confusion matrix。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx8dcczPph22"
      },
      "source": [
        "y_true = [2, 1, 0, 2, 2, 0, 1, 1]\n",
        "y_pred = [0, 1, 0, 2, 2, 0, 2, 1]\n",
        "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3).numpy()\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISJYZDDph23"
      },
      "source": [
        "建立plot_confusion_matrix函式：將剛剛上方計算的Confusion matrix陣列以Matplotlib圖片來表示，而Confusion matrix中的數字改成百分比型式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht1Ombw_ph24"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    \"\"\"\n",
        "    產生一張圖表示的Confusion matrix\n",
        "    \n",
        "    Args:\n",
        "    cm (shape = [n, n]): 傳入Confusion matrix\n",
        "    class_names (shape = [n]): 傳入類別\n",
        "    \"\"\"\n",
        "    # 標準化confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    tick_index = np.arange(len(class_names))\n",
        "    # matplotlib 3.1.1 bug，如果不設定ylim在[-0.5~2.5]，圖片y軸範圍會被縮小成[0~2]\n",
        "    plt.ylim([-0.5, 2.5])\n",
        "    # Y軸顯示類別名稱\n",
        "    plt.yticks(tick_index, class_names)\n",
        "    # X軸顯示類別名稱，並將類別名稱旋轉45度(避免文字重疊)\n",
        "    plt.xticks(tick_index, class_names, rotation=45)\n",
        "    # 再圖片右邊產生一條顏色刻度條\n",
        "    plt.colorbar()\n",
        "\n",
        "    # 在每一格Confusion matrix輸入預測百分比\n",
        "    threshold = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            # 如果格內背景顏色太深使用白色文字顯示，反之使用黑色文字\n",
        "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "            \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    # 將圖片的位置進行調整，避免x或y軸的文字被遮擋\n",
        "    plt.tight_layout()\n",
        "    return figure\n",
        "\n",
        "# Example\n",
        "img = plot_confusion_matrix(cm, [0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FysfWKUJph25"
      },
      "source": [
        "建立plot_to_image函數：將Matplotlib圖片轉TensorFlow型式的圖片，這樣才能夠透過tf.summary.image紀錄影像到TensorBoard。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2OXSqSzph25"
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    \"\"\"將Matplotlib plot的圖片轉TensorFlow的張量格式\"\"\"\n",
        "    # 將Matplotlib plot的圖片以PNG的格式儲存到記憶體中\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # 關閉plt圖片，防止圖片直接顯示在Jupyter notebook介面中\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # 將記憶體中的資料轉成TensorFlow格式\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS1rjP9eph26"
      },
      "source": [
        "# Example\n",
        "y_true = [2, 0, 2, 2, 0, 1]\n",
        "y_pred = [0, 0, 2, 2, 0, 2]\n",
        "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3).numpy()\n",
        "img = plot_confusion_matrix(cm, [0, 1, 2])\n",
        "img_show = plot_to_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW33f8I3ph26"
      },
      "source": [
        "### 創建Callback函數\n",
        "創建回調函數：訓練過程中每個epoch結束，會產生一張Confusion matrix的圖片，並將圖片紀錄在Tensorboard上。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9K09ZjYph26"
      },
      "source": [
        "class ConfusionMatrix(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, log_dir, test_data, class_name):\n",
        "        super(ConfusionMatrix, self).__init__()\n",
        "        self.log_dir = log_dir\n",
        "        self.test_data = test_data\n",
        "        self.class_names = class_name\n",
        "        self.num_classes = len(class_name)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        path = os.path.join(self.log_dir, 'confusion_matrix')\n",
        "        # 創建TensorBoard紀錄檔\n",
        "        self.writer = tf.summary.create_file_writer(path)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # 計算Confusion matrix\n",
        "        total_cm = np.zeros([10, 10])\n",
        "        for x, y_true in self.test_data:\n",
        "            y_pred = self.model.predict(x)\n",
        "            y_pred = np.argmax(y_pred, axis=1)\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "            cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=self.num_classes).numpy()\n",
        "            total_cm += cm\n",
        "        \n",
        "        # 將Confusion matrix轉成Matplotlib圖片\n",
        "        figure = plot_confusion_matrix(total_cm, class_names=self.class_names)\n",
        "        # 將Matplotlib圖片轉成TensorFlow型式的圖片\n",
        "        cm_image = plot_to_image(figure)\n",
        "\n",
        "        # 將圖片紀錄在TensorBoard log中\n",
        "        with self.writer.as_default():\n",
        "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4pJGzZph27"
      },
      "source": [
        "### 訓練網路模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GC9PPN0ph27"
      },
      "source": [
        "載入CIFAR-10數據集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU7cyX20ph27"
      },
      "source": [
        "# 將train Data重新分成9:1等分，分別分給train data, valid data\n",
        "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
        "# 取得訓練數據，並順便讀取data的資訊\n",
        "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
        "# 取得驗證數據\n",
        "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
        "# 取得測試數據\n",
        "test_data = tfds.load(\"cifar10\", split=tfds.Split.TEST)\n",
        "# 取得CIFAR-10數據集的類別\n",
        "class_name = info.features['label'].names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEFfhD5oph28"
      },
      "source": [
        "Dataset 設定；"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O2xmmGeph28"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
        "batch_size = 64  # 批次大小\n",
        "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
        "\n",
        "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
        "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
        "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "test_data = test_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd68X8kQph29"
      },
      "source": [
        "建立網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIObHocCph29"
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
        "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_mSdkgGph2-"
      },
      "source": [
        "建立Callback function："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskNXtFxph2-"
      },
      "source": [
        "# 儲存訓練記錄檔\n",
        "logs_dirs = 'lab7-logs-images'\n",
        "model_cbk = keras.callbacks.TensorBoard(logs_dirs)\n",
        "# 儲存Confusion matrix圖片\n",
        "save_cm = ConfusionMatrix(logs_dirs, test_data, class_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "griUwzJtph2_"
      },
      "source": [
        "設定訓練使用的優化器、客自化損失函數和客自化指標函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6U44BKjph2_"
      },
      "source": [
        "model_1.compile(keras.optimizers.Adam(), \n",
        "                loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2-cgcQtph2_"
      },
      "source": [
        "訓練網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQmwTc6vph3A"
      },
      "source": [
        "model_1.fit(train_data,\n",
        "            epochs=100, \n",
        "            validation_data=valid_data,\n",
        "            callbacks=[model_cbk, save_cm])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy_n4ZOD2BTh"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzugF3ROph3A"
      },
      "source": [
        "# 實驗二：使用TensorBoard超參數調校工具來訓練多個網路模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlQj4IA82Dxz"
      },
      "source": [
        "tensorboard --logdir lab7-logs-hparams/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3piTKlxBph3B"
      },
      "source": [
        "### Import必要套件："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-7o8FaRph3B"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# 從資料夾中的preprocessing.py檔案中Import parse_aug_fn和parse_fn函數\n",
        "from preprocessing import parse_aug_fn, parse_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnpX41dCph3B"
      },
      "source": [
        "### Import TensorBoard超參數工具所需要的套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jhoh1dMph3C"
      },
      "source": [
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OCvIoxUph3C"
      },
      "source": [
        "### 設定TensorBoard超參數調校"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaGDTxPJph3C"
      },
      "source": [
        "hparam_ia = hp.HParam('Imgae_Augmentation', hp.Discrete([False, True]))\n",
        "hparam_bn = hp.HParam('Batch_Normalization', hp.Discrete([False, True]))\n",
        "hparam_init = hp.HParam('Weight_Initialization', hp.Discrete(['RandomNormal_0.01std', 'glorot_normal', 'he_normal']))\n",
        "hparam_lr = hp.HParam('Learning_Rate', hp.Discrete([0.001, 0.01, 0.03]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8yTfwnph3C"
      },
      "source": [
        "### 將實驗摘要寫入紀錄檔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywMytSldph3D"
      },
      "source": [
        "metric = 'Accuracy'\n",
        "log_dirs = \"lab7-logs-hparams/hparam_tuning\"\n",
        "with tf.summary.create_file_writer(log_dirs).as_default():\n",
        "    hp.hparams_config(\n",
        "        hparams=[hparam_ia, hparam_bn, hparam_init, hparam_lr],\n",
        "        metrics=[hp.Metric(metric, display_name='Accuracy')],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRs8AD8o3HxW"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73RaYjC73WP6"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HVbHnZG26fS"
      },
      "source": [
        "tensorboard --logdir lab7-logs-hparams/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jor0KC_7ph3D"
      },
      "source": [
        "### 訓練網路模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4502CNIph3D"
      },
      "source": [
        "準備訓練資料，分別為「沒有影像增強」和「有影像增強」的訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPkZcIW7ph3E"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
        "batch_size = 64  # 批次大小\n",
        "# 將train Data重新分成1:9等分，分別分給valid data, train data\n",
        "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
        "\n",
        "# 取得訓練數據\n",
        "train_data_noaug, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
        "train_data_aug = tfds.load(\"cifar10\", split=train_split)\n",
        "# 取得驗證數據\n",
        "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
        "\n",
        "train_num = int(info.splits['train'].num_examples / 5) * 4  # 訓練資料數量\n",
        "\n",
        "train_data_noaug = train_data_noaug.shuffle(train_num)  # 打散資料集\n",
        "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
        "train_data_noaug = train_data_noaug.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "train_data_noaug = train_data_noaug.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_data_aug = train_data_aug.shuffle(train_num)  # 打散資料集\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "train_data_aug = train_data_aug.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "train_data_aug = train_data_aug.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGGuBN30ph3E"
      },
      "source": [
        "客製化超參數回調函式：用於紀錄每一次訓練模型的超參數數值和最終訓練結果的指標值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uePUMSWph3E"
      },
      "source": [
        "class HyperparameterCallback(tf.keras.callbacks.Callback):\n",
        "    # 類別創建時調用\n",
        "    def __init__(self, log_dir, hparams):\n",
        "        super(HyperparameterCallback, self).__init__()\n",
        "        self.log_dir = log_dir\n",
        "        self.hparams = hparams\n",
        "        self.best_accuracy = 0\n",
        "        self.writer = None\n",
        "        \n",
        "    # 訓練開始前調用\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
        "\n",
        "    # 每一個Epcoh結束後調用\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_accuracy = logs.get('val_categorical_accuracy')\n",
        "        if current_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy = current_accuracy\n",
        "            \n",
        "    # 訓練結束時調用\n",
        "    def on_train_end(self, logs=None):\n",
        "        with self.writer.as_default():\n",
        "            hp.hparams(self.hparams)  # record the values used in this trial\n",
        "            tf.summary.scalar(metric, self.best_accuracy, step=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVTlECFzph3F"
      },
      "source": [
        "建立一個函式負責創建、編譯和訓練網路模型，網路層配置如下：\n",
        "- keras.Input：輸入層(輸入影像大小為32x32x3)。\n",
        "- layers.Conv2D：卷積層(使用ReLU激活函數，以及3x3大小的kernel)。\n",
        "- layers.MaxPool2D：池化層(對特徵圖下採樣)。\n",
        "- layers.Flatten：扁平層(特徵圖轉成一維Tensor)。\n",
        "- layers.Dropout：Dropout層(每次訓練隨機丟棄50%網路)。\n",
        "- layers.Dense：全連接層(隱藏層使用ReLU激活函數，輸出層使用Softmax激活函數)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbpFgRXhph3F"
      },
      "source": [
        "def train_test_model(logs_dir, hparams):\n",
        "    \"\"\"\n",
        "    logs_dir:傳入目前執行的任務log檔的位置\n",
        "    hparams:傳入超參數\n",
        "    \"\"\"\n",
        "    # 指派網路模型初始化的方法\n",
        "    if hparams[hparam_init] == \"glorot_normal\":\n",
        "        init = keras.initializers.glorot_normal()\n",
        "    elif hparams[hparam_init] == \"he_normal\":\n",
        "        init = keras.initializers.he_normal()\n",
        "    else:\n",
        "        init = keras.initializers.RandomNormal(0, 0.01)\n",
        "\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(64, (3, 3), kernel_initializer=init)(inputs)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), kernel_initializer=init)(x)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(256, (3, 3), kernel_initializer=init)(x)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), kernel_initializer=init)(x)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), kernel_initializer=init)(x)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, kernel_initializer=init)(x)\n",
        "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "    # 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
        "    model = keras.Model(inputs, outputs, name='model')\n",
        "\n",
        "    # 儲存訓練記錄檔\n",
        "    model_tb = keras.callbacks.TensorBoard(log_dir=logs_dir, write_graph=False)\n",
        "\n",
        "    # 儲存最好的網路模型權重\n",
        "    model_mckp = keras.callbacks.ModelCheckpoint(logs_dir +'/best-model.hdf5', \n",
        "                                                 monitor='val_categorical_accuracy', \n",
        "                                                 save_best_only=True, \n",
        "                                                 mode='max')\n",
        "    \n",
        "    # 設定停止訓練的條件(當Accuracy超過30迭代沒有上升的話訓練會終止)\n",
        "    model_els = keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy' , \n",
        "                                              min_delta=0, \n",
        "                                              patience=30, \n",
        "                                              mode='max')\n",
        "    # 客自化超參數回調函式，紀錄訓練模型的超參數和指標(準確率)\n",
        "    model_hparam = HyperparameterCallback(logs_dir + 'hparam_tuning', hparams)\n",
        "\n",
        "\n",
        "    # 設定訓練使用的優化器、損失函數和指標函數\n",
        "    # 優化器學習率為超參數：0.001、0.01或0.03\n",
        "    model.compile(keras.optimizers.Adam(hparams[hparam_lr]), \n",
        "                  loss=keras.losses.CategoricalCrossentropy(), \n",
        "                  metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "    \n",
        "    # 超參數：使用「經過影像增強的數據」或「不經過影像增強的數據」訓練網路\n",
        "    if hparams[hparam_ia]:\n",
        "        history = model.fit(train_data_aug,\n",
        "                            epochs=2, \n",
        "                            validation_data=valid_data,\n",
        "                            callbacks=[model_tb, model_mckp, model_els, model_hparam])\n",
        "    else:\n",
        "        history = model.fit(train_data_noaug,\n",
        "                            epochs=2, \n",
        "                            validation_data=valid_data,\n",
        "                            callbacks=[model_tb, model_mckp, model_els, model_hparam])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "723kc-Tjph3G"
      },
      "source": [
        "訓練36種不同參數的網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrHTEePwph3G"
      },
      "source": [
        "session_id = 1  # 訓練任務的id\n",
        "for ia in hparam_ia.domain.values:\n",
        "    for bn in hparam_bn.domain.values:\n",
        "        for init in hparam_init.domain.values:\n",
        "            for lr in hparam_lr.domain.values:\n",
        "                # 顯示目前訓練任務id\n",
        "                print('--- Running training session {}'.format(session_id))\n",
        "                # 設定本次訓練的超參數\n",
        "                hparams = {hparam_ia: ia, hparam_bn: bn, hparam_init: init, hparam_lr: lr}\n",
        "                # 儲放紀錄檔的位置\n",
        "                logs_dir = os.path.join(\"lab7-logs-hparams\", \"run-{}\".format(session_id))\n",
        "                # 建立、編譯及訓練網路模型\n",
        "                train_test_model(logs_dir, hparams)\n",
        "                session_id += 1  # id+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}